---
title: "Investigating Indie"
output: 
  flexdashboard::flex_dashboard
---

```{r setup, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(ggplot2)
library(spotifyr)
library(compmus)
library(plotly)
library(gridExtra)
library(dplyr)
library(tidymodels)
library(ggdendro)
library(heatmaply)

folk <- get_playlist_audio_features("", "6P82OCSEpo1VrZ4TZ2W5jK")
pop <- get_playlist_audio_features("", "3HDdTtyB76aLDc4wpGFCX4")
rock <- get_playlist_audio_features("","5dMoFfrgm8aOOkneQjt6LT")

indie <-
  bind_rows(
    folk |> mutate(category = "Indie Folk"),
    pop |> mutate(category = "Indie Pop") |> slice_head(n = 50),
    rock |> mutate(category= "Indie Rock")
  ) 
```


Introduction
===================================== 

### What makes a song "Indie"? 
There is an ongoing debate on whether indie music can be considered a genre. Indie is short for “independent” and refers to music released by an artist independently rather than with a record label. Some bands that are considered to be indie, such as Arcade Fire, however, work with a record label. This begs the question: What makes indie music indie? Some argue that indie music has a specific sound, but what are its defining characteristics that allows Spotify to create “Indie” playlists? I hope to investigate this question with my corpus containing songs from three different indie sub-genre playlists created by Spotify: “Indie Rock Mix,” “Indie Pop Mix,” and “Indie Folk Mix.” Comparing songs from these different sub-genres will clarify what characteristics of a song Spotify considers to be indie. The main limitation of my investigation is that the songs in the playlists are recommended by Spotify for my specific account. Hence, it may not reflect the most popular indie songs nor be representative of indie music as a whole. “The Less I Know the Better” by Tame Impala is a typical indie song in my corpus, because it cannot be tied to another genre. Two atypical songs are “Sunflower” by Harry Styles and “Work Song” by Hozier, because neither of these artists are considered to be indie artists. These songs will be good to analyze since they may have the characteristics of a typical indie song, but they are made by non-indie artists.
  
Indie folk combines the catchy melodies of indie rock with the acoustical sounds of contemporary folk music.
  
  
```{r}

```


Comparing the Three Playlists {.storyboard}
===========================================================

### Indie Rock is Energetic {data-commentary-width=400}
```{r}
dens_energy <- ggplot(indie, aes(x = category, y=energy, color = category)) + geom_boxplot() +
  labs(x = "Energy", y = "Density", 
       title = "Comparing the Distribution of Energy Between Indie Subgenres") 
ggplotly(dens_energy)
```

*** 
Energy is a Spotify track-level feature measured between 0 to 1, with 0 being the lowest energy and 1 the highest. This boxplot shows that energy is widespread over the Indie genre as a whole. A song's energy cannot tell us whether it belongs under the general "Indie" label. What it does show, however, is a difference in energy between the three playlists. Spotify's "Indie Rock" playlist contains the songs with the most energy, with a mean energy of 0.8 and a minimum energy of 0.5. On the other hand, "Indie Folk" has the songs with the least energy with a mean energy of 0.4 and a minimum energy of 0.06. Lastly, "Indie Pop" has its songs' energies spread out the most with a mean of 0.6, a maximum energy of 0.9, and a minimum energy of 0.1. As an indie listener, this difference in energy is not surprising. Indie folk has a calm and mellow feel and usually uses light acoustic instruments, while indie rock can be louder with a faster tempo and more energetic instruments, such as the drumbs and the electric guitar. Indie pop can have both a calm and energetic feel when listening to it, for example the song "j's lullaby" by Delaney Bailey is very slow and quiet, while the song "I'm In Love With You" by The 1975 is much more upbeat.



### Indie Rock Has The Energy, Indie Folk Is For The Feels, Indie Pop Is Undecided {data-commentary-width=400}
```{r}
energy_valence <- ggplot(indie, aes(x = energy, y = loudness, color=valence, label = track.name)) + geom_point() + facet_wrap(~category) + scale_color_gradient(low = "yellow", high = "purple") + labs(x = "Energy", y = "Loudness") + geom_smooth(method=lm)
ggplotly(energy_valence)
```

***

This graph shows a consistent trend in all three sub-genres: as loudness increases, so does energy. Consistent with the last histogram, energy and loudness are widespread over the Indie genre as a whole. What can be observed again is that Spotify's "Indie Rock" playlist holds the songs with the most energy and loudness, followed by "Indie Pop" and "Indie Folk." Hence, the energy and loudness features can help us distinguish Indie songs from each other and categorize them into sub-genres. 

Indie folk separates itself from the other two sub-genres through the valence feature. Valence is measured from 0.0 to 1.0 and describes the musical positivity of a track. A song with a high valence (purple in this graph) is described as sounding happy, while a track with a low valence (yellow) sounds sad. Compared to rock and pop, most of the indie folk songs have a negative valence. In other words, Indie Folk is a sad sub-genre.

The song "j's lullaby" by Delaney Bailey is a clear outlier in this graph. It has the least energy and loudness by far compared to not only the other indie pop songs but also compared to the songs in the other two sub-genres. It is indeed a very mellow and calm song. Another atypical song is "Naked as We Came" by Iron & Wine since it is one of the few songs that is low in energy and loudness but has a positive valence. These specific songs are analyzed further in the "Comparing Pitch" tab.



Comparing Pitch {data-navmenu="A Closer Look"}
==================================

Column {data-width=700}
-----------------------------------
### Energetic Indie Has A More Colorful Pitch Than Quiet Indie
```{r}
j_lullaby <-
  get_tidy_audio_analysis("7LNm1oWd6PniO9wRYpNY5o") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

j_lullaby_plot <- j_lullaby |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "\"j's lullaby\" by Delaney Bailey", subtitle = "Indie Pop, Lowest Energy, Low Valence") +
  theme_minimal() +
  scale_fill_viridis_c() + theme(plot.title = element_text(face="bold", size=8), plot.subtitle = element_text(size=6), axis.title = element_text(size=6), axis.text = element_text(size=6) , legend.title = element_text(size=6), legend.key.size = unit(0.3, 'cm'), legend.text = element_text(size=5))

live_once <-
  get_tidy_audio_analysis("4fPBB44eDH71YohayI4eKV") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

live_once_plot <- live_once |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "\"You Only Live Once\" by The Strokes", subtitle = "Indie Rock, Highest Energy, High Valence") +
  theme_minimal() +
  scale_fill_viridis_c() + theme(plot.title = element_text(face="bold", size=8), plot.subtitle = element_text(size=6), axis.title = element_text(size=6), axis.text = element_text(size=6) , legend.title = element_text(size=6), legend.key.size = unit(0.3, 'cm'), legend.text = element_text(size=5))

naked <- get_tidy_audio_analysis("4FuBIkfhZMoRgrDiHL6TYG") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

naked_plot <- naked |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "\"Naked As We Came\" by Iron & Wine", subtitle = "Indie Folk, Low Energy, High Valence") +
  theme_minimal() +
  scale_fill_viridis_c() + theme(plot.title = element_text(face="bold", size=8), plot.subtitle = element_text(size=6), axis.title = element_text(size=6), axis.text = element_text(size=6) , legend.title = element_text(size=6), legend.key.size = unit(0.3, 'cm'), legend.text = element_text(size=5))

wolf <- get_tidy_audio_analysis("03wKMRNYVvw6s9nm4I4jUS") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

wolf_plot <- wolf |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "\"Wolf Like Me\" by TV On The Radio", subtitle = "Indie Rock, High Energy, Low Valence") +
  theme_minimal() +
  scale_fill_viridis_c() + theme(plot.title = element_text(face="bold", size=8), plot.subtitle = element_text(size=6), axis.title = element_text(size=6), axis.text = element_text(size=6) , legend.title = element_text(size=6), legend.key.size = unit(0.3, 'cm'), legend.text = element_text(size=5))

grid.arrange(j_lullaby_plot, live_once_plot, naked_plot, wolf_plot, ncol=2)
```

Column {data-width=400 .tabset}
-----------------------------------
### Chromagrams
A chromagram is a visual representation of the pitch of a piece of music. It shows how much energy is contained in each pitch class at any given moment. These chromagrams of four different songs are interesting to compare, as each song has a different extreme level of valence and energy.

As discussed earlier, "j's lullaby" by Delaney Bailey is the song in the corpus with the lowest energy and valence. On the opposite extreme, "You Only Live Once" by The Strokes is one of the songs with the highest energy and highest valence. The other two songs displayed have an atypical combination of opposing energy and valences. The Indie Folk song "Naked As We Came" has low energy and high valence, while "Wolk Like Me" has high energy and low valence.

When comparing these four chromagrams at first glance, we can see that the two songs with high energy, "You Only Live Once" and "Wolf Like Me," have their signal's energy more widespread over all the pitch classes. Overall, their chromagrams have hints of yellow in almost every pitch class, while "j's lullaby" and "Naked As We Came" chromograms have their energy more contained in specific pitch classes. This may be because of the instruments played and the tuning of the instruments. "j's lullaby" and "Naked As We Came" only have the acoustic guitar playing and vocals, while "You Only Live Once" and "Wolf Like Me" use the electric guitar and drums which could lead to a more noisy chromagram.


### Individual Song Analysis
"j's lullaby" has most of its energy focused in pitch class A-flat, and some of its energy in D-flat. When listening to the song, the A-flat and D-flat major keys give the song a calm, sad, nostalgic tone, which explains the negative valence measure.

"Naked As We Came" has most of its energy contained in pitch classes E and B. The song is indeed written in an E major key. Although the song is low in energy and has a calm tone to it, the E major key gives the song a joyful mood. The song is structured as follows: Verse 1, Chorus, Verse 2, Chorus. Verses 1 and 2 are sung by a male vocalist, and a female voice joins at a different pitch during the chorus. In the chromagram, we observe this pitch change for both choruses: at around 45 seconds the energy moves from pitch class E to F-sharp, and then moves back to E at 65 seconds for Verse 2, this happens again 100 seconds into the song for the second chorus. 

"You Only Live Once" has most of its energy contained in pitch classes E and B. During the first 20 seconds, the song's energy is mostly contained in E, and then it splits alternating between E and B. At 160 seconds, the song abruptly moves all of its energy contained in pitch class B. This shift in pitch marks the last 30 seconds of the song characterized by a build up of energy. This Strokes song is written in B major, which helps set the harsh and angry tone the song projects. The E pitch class that was detected by Spotify, which is usually characterized by a happy tone, could indicate why the valence of the song is positive.

"Wolf Like Me" has most of its energy contained in pitch class B with some alternation to pitch G. Because the song is written in B major, which has an angry tone, this could be a reason for Spotify's valence measure being low, despite being high in energy.

Overall, the four songs do not have too much pitch variation, with most of their energies contained in one or two pitch classes. This could be an indicator of the "Indie" genre. As an indie listener, I would agree with this observation as most indie songs are written based on one key and do not deviate much from it.


Self-Similarity Matrices {.storyboard data-navmenu="A Closer Look"}
==================================

### Typical Indie Rock: Simple Chroma & Complex Timbre {data-commentary-width=400}
``` {r}
a_punk <-
  get_tidy_audio_analysis("3AydAydLzyyZutA0375XIz") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

a_punk_chroma <- a_punk |>
  compmus_self_similarity(pitches, "cosine") |> # change timbre/pitches
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Chroma-based Self-Similarity Matrix") + theme(title = element_text(size = 8))

a_punk_timbre <- a_punk |>
  compmus_self_similarity(timbre, "cosine") |> # change timbre/pitches
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Timbre-Based Self-Similarity Matrix") + theme(title = element_text(size = 8))

grid.arrange(top = "\"A-Punk\" by Vampire Weekend", a_punk_chroma, a_punk_timbre, ncol=2)
```

***
A self-similarity shows the degree of similarity between different parts of a musical piece. It helps us understand how a song is structured through both its pitch (chroma) and timbre.

The self-similarity matrices on the left are those of a song by the Vampire Weekend. The Vampire Weekend is a known Indie Rock band. There debut album "Vampire Weekend" was independently released in 2008, hence officially falling under the "Indie" label. "A-Punk" is an energetic and youthful song that starts with a light-hearted guitar riff which is joined by drums and vocals.

It is short song with the following structure: verse, chorus, refrain, verse, chorus refrain. We can see this pattern in the chroma-based matrix: 0-40s is verse 1, 40-60s is chorus & refrain, 60-100s is verse 2, and then back to chorus and refrain. The chroma-based matrix helps us see this clear structure of the song. This pattern is most likely why the song has become so popular. The simple structure makes the song simple to follow and fun to dance to.

The timbre-based matrix is more interesting to look at. At 40 seconds, the first change in timbre is marked by the flute entering the song, which gives the song an extra layer of timbre complexity. At 60 seconds, the cymbal is abruptly played alone, followed by a vocal "hey hey hey" with no instrumental background, and then the drums come back in to move onto the next verse. This is the part of the song that gives the listener anticipation for what is coming next. After the second verse, the flute comes back followed by the "hey hey hey." At the end of the song (~130s), the cymbal comes back abruptly alone marking the end of the song.

This typical indie rock song shows that the changes pitches and vocals are not as important as the changes in timbre in indie rock. The instruments of the bands play an important role in creating a successful indie rock song.


### Typical Indie Folk: Simple Chroma & Simple Timbre {data-commentary-width=400}
``` {r}
flightless <-
  get_tidy_audio_analysis("1fEGtTZjrjJW8eUeewnNJR") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

flightless_chroma <- flightless |>
  compmus_self_similarity(pitches, "cosine") |> # change timbre/pitches
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Chroma-based Self-Similarity Matrix") + theme(title = element_text(size = 8))

flightless_timbre <- flightless |>
  compmus_self_similarity(timbre, "cosine") |> # change timbre/pitches
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Timbre-Based Self-Similarity Matrix") + theme(title = element_text(size = 8))

grid.arrange(top="\"Flightless Bird, American Mouth\" by Iron & Wine", flightless_chroma, flightless_timbre, ncol=2)
```

*** 
Iron & Wine is an American indie folk singer-songwriter. His songs have the typical indie folk sound, which is confirmed by the fact that 2 out of the 50 songs in Spotify's "Indie Folk" playlist are his, but he has never been an independent artist. His first album "The Creek Drank the Cradle" was released in 2002 on the Sub Pop label. Hence, "Flightless Bird, American Mouth" by Iron & Wine is an interesting song to analyze as it is labeled an indie song, but was not independently released. 

The self-similarity matrices we see on the left are to be expected. The only two instruments used during the song are the guitar and tambourine and the vocals indicate the structure of the song: verse 1, chorus, verse 2, chorus. Both verses have the same melody, but different lyrics. The chroma-based self-similarity matrix shows the constant pitch used throughout the song, as it does indicate a clear structure to the song. The timbre-based matrix is also quite unvaried further demonstrating the consistency and repetition of a typical Indie song.


### Typical Indie Pop: Simple Chroma & Simple Timbre {data-commentary-width=400}
``` {r}
in_love <-
  get_tidy_audio_analysis("0uBdQzKghx88d2Lp8SLFKJ") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

in_love_chroma <- in_love |>
  compmus_self_similarity(pitches, "cosine") |> # change timbre/pitches
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Chroma-based Self-Similarity Matrix") + theme(title = element_text(size = 8))

in_love_timbre <- in_love |>
  compmus_self_similarity(timbre, "cosine") |> # change timbre/pitches
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Timbre-Based Self-Similarity Matrix") + theme(title = element_text(size = 8))

grid.arrange(top="\"I'm In Love With You\" by The 1975", in_love_chroma, in_love_timbre, ncol=2)
```

*** 
The third song we will analyze is "I'm In Love With You" by The 1975. The 1975 is a popular indie band. CONTINUE DESCRIPTION


Indie Keys and Chords {.storyboard data-navmenu="A Closer Look"}
=====================================

### Indie Keys 
```{r}
key_histogram <- ggplot(indie, aes(x=key, color=category,fill=category)) + geom_histogram(binwidth = 1, alpha=0.6) + scale_x_continuous(breaks = c(0:11), labels=c("C","C#","D","D#","E","F","F#","G","G#","A","A#","B")) + 
  facet_wrap(~category) + labs(y = "Count", x="Key", title = "Comparing the Distribution of Key Between Indie Subgenres")
ggplotly(key_histogram)
```
***
This histogram shows the distribution of keys in each indie subgenre playlist. The most common used keys in Indie Pop are C and C#. This is to be expected, as C and G major are the most common key used in pop music. Although G major is one of the most common keys used in pop music, G is surprisingly the least common key in Indie Pop. Hence, indie pop follows the pop-genre norm when it comes to having songs with C as a key, but the minority of the songs are in the key of G. The other two indie genres have a less distinct majority key. Indie Folk has the majority of its songs in the keys C, D, E, and F, and the minority in keys G# and A#. Indie Rock has the majority of its songs in the keys C, D, G, and A, and the minority in keys D#, G#, and A#. C is thus the most common key used in all three genres, followed by D. Overall, the keys used in each subgenre are widespread, with some more and others less common.


### "White Winter Hymnal" by Fleet Foxes {data-commentary-width=500}
``` {r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

# 0GegHVxeozw3rdjte45Bfx - winter_hymnal - chord_templates interesting

winter_hymnal <-
  get_tidy_audio_analysis("0GegHVxeozw3rdjte45Bfx") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )


winter_hymnal |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Chordogram of \"White Winter Hymnal\" by Fleet Floxes")

```

*** 
A chordogram is a visual representation of the different chords used in a song at any given time. These are made by comparing the chords in the audio recording of the song to a template of predefined chord models. The darker sections in the chordogram are, the more similar those chords are to the template, meaning this chord is being played at a particular time.

"White Winter Hymnal" by Fleet Foxes is another typical indie folk song. It is very repetitive in its melody and lyrics. Its structure consists of an intro followed by the chorus three times. This is very characteristic of indie folk music. The only thing that truly changes throughout the song is the chords used throughout. This chordogram shows that "White Winter Hymnal" uses distinct chords during distinct sections of the song. From 0 to 30s, the song is in an E7 chord, this is the intro of the song. From 30 to 40s, the song goes down to an A7 chord, marking a transition between the intro and the first chorus. From 40 to 60s, the chord goes back to E7 for the chorus. From 60 to 70s, the song goes further down to an F# minor, marking another transtion from the first chorus to the second chorus, and so on. What is interesting to see is that the band marking the chord G-flat 7 is dark throughout the whole chordogram. This is the base chord the song is centered around and then the variation throughout the song indicates the different sections of the song.


Exploring Tempo {.storyboard data-navmenu="A Closer Look"}
=====================================

### Indie Rock is the Fastest, Folk is more Relaxed
```{r}

temp <- indie %>%
  group_by(category) %>%
  summarise(temp_mean = mean(tempo))

tempo_hist <- ggplot(indie, aes(x=tempo, color=category,fill=category)) +
  geom_histogram(binwidth = 10, alpha=0.6) +
  geom_density() +
  labs(y = "Count", x="Tempo", title = "Comparing the Distribution of Tempo Between Indie Subgenres") +
  geom_vline(temp, mapping = aes(xintercept = temp_mean),col="purple") + 
  facet_wrap(~category)

ggplotly(tempo_hist)
```

***
Most popular songs today have a tempo between 100 and 140bpm. This histogram shows that the Indie genre tempo generally lies between 90 and 160bpm, which is consistent with the popular tempo. The means of all three playlists, which are represented by the purple line in the graph, are close to 120bpm. Indie rock has the fastest tempo with an average of 127bpm, followed by pop with 124bpm, and lastly folk has slowest mean tempo of 116bpm. A tempo between 109-132bpm is known as "allegro" in Italian musical terms and means fast, quick, and bright. This describes the tempo of most of the Indie songs in the corpus. Indie Folk is a slower form of the genre as its mode is centered around 100bpm; 20% of the songs in this playlist have a tempo of 100bpm. This is considered "allegretto," or moderately fast. Indie rock and pop have their modes centered around 120bpm. Indie pop has the most widespread tempo with two outliers: "Maybe I'm Lonely" by Rachel Chinouriri with a tempo of 50bpm, and "Petrified" by Omar Apollo with a tempo of 200bpm. Indie rock has one song with a tempo of 200bpm called "The Rover" by Interpol. Overall, however, the three playlists follow the same histogram pattern of tempo. 


<!-- ### "No Cars Go" by Arcade Fire -->
<!-- ``` {r} -->
<!-- no_cars_go <- get_tidy_audio_analysis("51xBgzcyzojRpqFW2ICQAB") -->

<!-- no_cars_go |> -->
<!--   tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) |> -->
<!--   ggplot(aes(x = time, y = bpm, fill = power)) + -->
<!--   geom_raster() + -->
<!--   scale_fill_viridis_c(guide = "none") + -->
<!--   labs(x = "Time (s)", y = "Tempo (BPM)") + -->
<!--   theme_classic() -->

<!-- no_cars_go |> -->
<!--   tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |> -->
<!--   ggplot(aes(x = time, y = bpm, fill = power)) + -->
<!--   geom_raster() + -->
<!--   scale_fill_viridis_c(guide = "none") + -->
<!--   labs(x = "Time (s)", y = "Tempo (BPM)") + -->
<!--   theme_classic() -->
<!-- ``` -->


Zooming Back Out {.storyboard}
======================================
### Can Spotify's Audio Features Group Indie Sub-Genres? {data-commentary-width=400}
``` {r}
indie <-
  bind_rows(
    folk |> mutate(category = "Indie Folk", playlist_name = "Indie Folk") |> slice_head(n = 30),
    pop |> mutate(category = "Indie Pop", playlist_name = "Indie Pop") |> slice_head(n = 30),
    rock |> mutate(category= "Indie Rock", playlist_name = "Indie Rock") |> slice_head(n = 30)
  ) |> 
  add_audio_analysis()


# Note that you are not allowed to have duplicate songs in the dataset! 
indie |>
  count(track.name) %>%
  arrange(desc(n))

# Grab only track names where it's listed more than once
tracks_to_remove <- indie |>
  count(track.name) |>
  filter(n >= 2) %>%
  select(track.name)

indie <- indie %>%
  anti_join(tracks_to_remove)


# Similar to code from class, still trying to predict track.name but later we add on playlist name!
indie_juice <-
  recipe(
    track.name ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo,
    data = indie
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(indie |> mutate(track.name = str_trunc(track.name, 20))) |>
  juice() |>
  column_to_rownames("track.name")

indie_dist <- dist(indie_juice, method = "euclidean")

data_for_indie_clustering <- indie_dist |> 
  hclust(method = "average") |> # average for a balanced tree!
  dendro_data() 

playlist_data_for_join <- indie %>%
  select(track.name, playlist_name) %>%
  mutate(label = str_trunc(track.name, 20))

data_for_indie_clustering$labels <- data_for_indie_clustering$labels %>%
  left_join(playlist_data_for_join)

# Add factor so can use colouring! 
data_for_indie_clustering$labels$label <- factor(data_for_indie_clustering$labels$label)


data_for_indie_clustering |>
  ggdendrogram() +
  geom_text(data = label(data_for_indie_clustering), aes(x, y, 
                                                         label=label, 
                                                         hjust=0, 
                                                         colour=playlist_name), size=3) +
  coord_flip() + 
  scale_y_reverse(expand=c(0.2, 0)) +
  theme(axis.line.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        panel.background=element_rect(fill="white"),
        panel.grid=element_blank()) +
  labs(title = "Playlist Clustering") +
  guides(
    colour = guide_legend(
      title = "Playlist"
    )
  )
```

***
This graph corresponds to hierarchical clustering, which relies on unsupervised machine learning whereby unlabeled songs are grouped together based on their similarity in Spotify's audio feature measurements. In this cluster, the track names are written at the bottom of each branch, and the color corresponds to which playlist they belong to. The songs that are most similar to each other would be closer together at the end of the tree. Here we can observe that through Spotify's audio features, the songs in the "Indie Folk" playlist are clustered together, with most of the songs on top being colored in red. The songs in the "Indie Rock" playlist are also clearly grouped together in blue. This means that Spotify is able to use its audio features to distinguish the two indie sub-genres from each other. In contrast, the "Indie Pop" playlist does not have an obvious cluster. This is consistent with indie pop being spread out in energy and valence which we observed earlier. This could be because indie pop has a less recognizable "sound" to it. Wikipedia describes indie pop as "a music genre and subculture that combines guitar pop with DIY ethic in opposition to the style and tone of mainstream pop music." This "DIY ethic" could be the factor that distinguishes indie pop songs from each other. Artists could have a different spin to a pop sound, making each indie pop song sound slightly different and vary within Spotify's audio features. 



